[2025-04-12T12:01:12.695+0000] {local_task_job_runner.py:123} INFO - ::group::Pre task execution logs
[2025-04-12T12:01:12.708+0000] {taskinstance.py:2614} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: pollen_ingestion_dag.transform_pollen manual__2025-04-12T12:01:09.931994+00:00 [queued]>
[2025-04-12T12:01:12.712+0000] {taskinstance.py:2614} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: pollen_ingestion_dag.transform_pollen manual__2025-04-12T12:01:09.931994+00:00 [queued]>
[2025-04-12T12:01:12.712+0000] {taskinstance.py:2867} INFO - Starting attempt 1 of 2
[2025-04-12T12:01:12.717+0000] {taskinstance.py:2890} INFO - Executing <Task(BashOperator): transform_pollen> on 2025-04-12 12:01:09.931994+00:00
[2025-04-12T12:01:12.721+0000] {warnings.py:112} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:70: DeprecationWarning: This process (pid=66) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2025-04-12T12:01:12.722+0000] {standard_task_runner.py:72} INFO - Started process 67 to run task
[2025-04-12T12:01:12.722+0000] {standard_task_runner.py:104} INFO - Running: ['***', 'tasks', 'run', 'pollen_ingestion_dag', 'transform_pollen', 'manual__2025-04-12T12:01:09.931994+00:00', '--job-id', '795', '--raw', '--subdir', 'DAGS_FOLDER/pollen_ingestion_dag.py', '--cfg-path', '/tmp/tmpe6ej8io0']
[2025-04-12T12:01:12.725+0000] {standard_task_runner.py:105} INFO - Job 795: Subtask transform_pollen
[2025-04-12T12:01:12.761+0000] {task_command.py:467} INFO - Running <TaskInstance: pollen_ingestion_dag.transform_pollen manual__2025-04-12T12:01:09.931994+00:00 [running]> on host caedfbfc7792
[2025-04-12T12:01:12.807+0000] {taskinstance.py:3134} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='beni' AIRFLOW_CTX_DAG_ID='pollen_ingestion_dag' AIRFLOW_CTX_TASK_ID='transform_pollen' AIRFLOW_CTX_EXECUTION_DATE='2025-04-12T12:01:09.931994+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2025-04-12T12:01:09.931994+00:00'
[2025-04-12T12:01:12.808+0000] {taskinstance.py:732} INFO - ::endgroup::
[2025-04-12T12:01:12.809+0000] {subprocess.py:78} INFO - Tmp dir root location: /tmp
[2025-04-12T12:01:12.810+0000] {subprocess.py:88} INFO - Running command: ['/usr/bin/bash', '-c', 'docker run --rm -v $(pwd)/fastapi/credentials:/app/credentials -e GOOGLE_APPLICATION_CREDENTIALS=/app/credentials/fastapi-gcs-key.json -v $(pwd)/spark:/app gooutside-spark spark-submit /app/transform_pollen.py']
[2025-04-12T12:01:12.814+0000] {subprocess.py:99} INFO - Output:
[2025-04-12T12:01:13.046+0000] {subprocess.py:106} INFO - [38;5;6mspark [38;5;5m12:01:13.04 [0m[38;5;2mINFO [0m ==>
[2025-04-12T12:01:13.048+0000] {subprocess.py:106} INFO - [38;5;6mspark [38;5;5m12:01:13.04 [0m[38;5;2mINFO [0m ==> [1mWelcome to the Bitnami spark container[0m
[2025-04-12T12:01:13.049+0000] {subprocess.py:106} INFO - [38;5;6mspark [38;5;5m12:01:13.04 [0m[38;5;2mINFO [0m ==> Subscribe to project updates by watching [1mhttps://github.com/bitnami/containers[0m
[2025-04-12T12:01:13.051+0000] {subprocess.py:106} INFO - [38;5;6mspark [38;5;5m12:01:13.04 [0m[38;5;2mINFO [0m ==> Did you know there are enterprise versions of the Bitnami catalog? For enhanced secure software supply chain features, unlimited pulls from Docker, LTS support, or application customization, see Bitnami Premium or Tanzu Application Catalog. See https://www.arrow.com/globalecs/na/vendors/bitnami/ for more information.
[2025-04-12T12:01:13.075+0000] {subprocess.py:106} INFO - [38;5;6mspark [38;5;5m12:01:13.05 [0m[38;5;2mINFO [0m ==>
[2025-04-12T12:01:13.077+0000] {subprocess.py:106} INFO - 
[2025-04-12T12:01:14.159+0000] {subprocess.py:106} INFO - python3: can't open file '/app/transform_pollen.py': [Errno 2] No such file or directory
[2025-04-12T12:01:14.165+0000] {subprocess.py:106} INFO - 25/04/12 12:01:14 INFO ShutdownHookManager: Shutdown hook called
[2025-04-12T12:01:14.166+0000] {subprocess.py:106} INFO - 25/04/12 12:01:14 INFO ShutdownHookManager: Deleting directory /tmp/spark-df827d45-f0fd-4c00-a89d-336cb072cc36
[2025-04-12T12:01:14.298+0000] {subprocess.py:110} INFO - Command exited with return code 2
[2025-04-12T12:01:14.314+0000] {taskinstance.py:3313} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 768, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 734, in _execute_callable
    return ExecutionCallableRunner(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 424, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/bash.py", line 276, in execute
    raise AirflowException(
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 2.
[2025-04-12T12:01:14.323+0000] {taskinstance.py:1226} INFO - Marking task as UP_FOR_RETRY. dag_id=pollen_ingestion_dag, task_id=transform_pollen, run_id=manual__2025-04-12T12:01:09.931994+00:00, execution_date=20250412T120109, start_date=20250412T120112, end_date=20250412T120114
[2025-04-12T12:01:14.391+0000] {taskinstance.py:341} INFO - ::group::Post task execution logs
[2025-04-12T12:01:14.392+0000] {standard_task_runner.py:124} ERROR - Failed to execute job 795 for task transform_pollen (Bash command failed. The command returned a non-zero exit code 2.; 67)
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/task/task_runner/standard_task_runner.py", line 117, in _start_by_fork
    ret = args.func(args, dag=self.dag)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/cli/commands/task_command.py", line 483, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/cli/commands/task_command.py", line 256, in _run_task_by_selected_method
    return _run_raw_task(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/cli/commands/task_command.py", line 341, in _run_raw_task
    return ti._run_raw_task(
           ^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3006, in _run_raw_task
    return _run_raw_task(
           ^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 274, in _run_raw_task
    TaskInstance._execute_task_with_callbacks(
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3161, in _execute_task_with_callbacks
    result = self._execute_task(context, task_orig)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3185, in _execute_task
    return _execute_task(self, context, task_orig)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 768, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 734, in _execute_callable
    return ExecutionCallableRunner(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 424, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/bash.py", line 276, in execute
    raise AirflowException(
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 2.
[2025-04-12T12:01:14.438+0000] {local_task_job_runner.py:266} INFO - Task exited with return code 1
[2025-04-12T12:01:14.456+0000] {taskinstance.py:3901} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2025-04-12T12:01:14.457+0000] {local_task_job_runner.py:245} INFO - ::endgroup::
